AN√ÅLISE DE INDICADORES DE SA√öDE P√öBLICA COM PERSIST√äNCIA POLIGLOTA
Este reposit√≥rio cont√©m o projeto de TCC (Trabalho de Conclus√£o de Curso) intitulado "AN√ÅLISE DE INDICADORES DE SA√öDE P√öBLICA A PARTIR DE DADOS DO PORTAL DADOS.GOV.BR, COM FOCO NA PERSIST√äNCIA POLIGLOTA EM BANCOS DE DADOS NOSQL E RELACIONAIS".

O projeto consiste em um pipeline de ETL-A (Extra√ß√£o, Transforma√ß√£o, Carga e An√°lise) robusto, desenvolvido em Python e Pandas , que processa dados p√∫blicos de sa√∫de (Dengue/SINAN) e os persiste em uma arquitetura poliglota, utilizando MySQL e MongoDB para diferentes prop√≥sitos anal√≠ticos.





Autores:

Paulo Henrique Dantas Teodosio 

Wesley Gabriel Teixeira de Arag√£o 

Orientador:

Prof. Israel da Costa Cunha 

üèõÔ∏è Arquitetura da Solu√ß√£o
O n√∫cleo deste projeto √© a demonstra√ß√£o pr√°tica da persist√™ncia poliglota . Os dados n√£o s√£o apenas armazenados, mas transformados e direcionados para o banco de dados mais adequado para a tarefa anal√≠tica.

O pipeline processa 1.502.259 registros de notifica√ß√µes de Dengue de 2024.



Fonte de Dados: dados_dengue.json (1.4 GB, 121 colunas).


Motor ETL-A (Python/Pandas):

Extra√ß√£o: Leitura do JSON.


An√°lise (EDA): An√°lise de qualidade dos dados (ex: descoberta de 99,2% de dados de idade ausentes).



Mapeamento: Sele√ß√£o e renomea√ß√£o de ~25 colunas de interesse.


Enriquecimento: Jun√ß√£o (merge) com municipios.csv para adicionar nome_municipio e codigo_uf.

Transforma√ß√£o: Limpeza, decodifica√ß√£o (ex: NU_IDADE_N) e bifurca√ß√£o da l√≥gica de persist√™ncia.

Destino 1: MongoDB (Banco NoSQL)


Prop√≥sito: Reposit√≥rio de Data Science e an√°lise explorat√≥ria.



Modelagem: Os dados s√£o salvos "planos" (ex: sint_febre: '1'), preservando a granularidade para consultas flex√≠veis e de perfil cl√≠nico .


Destino 2: MySQL (Banco Relacional)


Prop√≥sito: Data Mart Anal√≠tico para BI e reporting.



Modelagem: M√∫ltiplas colunas de sintomas (ex: FEBRE, VOMITO) s√£o agregadas em um √∫nico campo do tipo JSON (sintomas_json) , otimizando o banco para consultas agregadas (GROUP BY) e relat√≥rios.


üöÄ Principais Features e Desafios Resolvidos

Processamento em Lote (Batch Processing): A carga de 1.5M de registros no MySQL falhou com o Erro 2055 (max_allowed_packet) . O pipeline resolve isso implementando a inser√ß√£o em lotes de 50.000 registros, garantindo a carga completa .



Enriquecimento de Dados: Traduz c√≥digos brutos (ID_MUNICIP) em dados leg√≠veis (nome_municipio), essencial para a an√°lise de indicadores.

Decodifica√ß√£o de Dados: Converte dados complexos do DataSUS (ex: NU_IDADE_N '1035' -> 35 anos) em formatos anal√≠ticos padronizados.

Pipeline Reexecut√°vel: Gra√ßas ao script preparar_mysql.py, a arquitetura pode ser destru√≠da e recriada de forma consistente.

üõ†Ô∏è Stack Tecnol√≥gico
Linguagem: Python 3.x

Processamento de Dados: Pandas, NumPy

Banco de Dados Relacional: MySQL

Banco de Dados NoSQL: MongoDB

Conectores Python: mysql-connector-python, pymongo

‚öôÔ∏è Configura√ß√£o e Instala√ß√£o
Clone o reposit√≥rio:

Bash
-------------------------------------------------------------
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
Instale as depend√™ncias:
-------------------------------------------------------------
Bash
-------------------------------------------------------
pip install pandas mysql-connector-python pymongo requests
(√â recomendado o uso de um ambiente virtual venv)
-------------------------------------------------------
Pr√©-requisitos:

Tenha inst√¢ncias locais do MySQL e MongoDB em execu√ß√£o.

Crie um banco de dados no MySQL chamado tcc_dengue.

Atualize as credenciais de banco de dados (usu√°rio, senha) no topo do carregar_dados.py e preparar_mysql.py.

Dados:

Coloque o arquivo de dados do SINAN na pasta raiz com o nome: dados_dengue.json.

(Opcional) O script baixar_csv.py pode ser usado para baixar o arquivo municipios.csv, ou voc√™ pode baix√°-lo manualmente.

‚ñ∂Ô∏è Como Executar o Pipeline
A execu√ß√£o deve seguir esta ordem:

Passo 1: Preparar o Banco de Dados MySQL Este script cria (ou recria) a tabela notificacoes no MySQL com o esquema correto, incluindo as colunas JSON e os campos de enriquecimento.

Bash
-----------------------------
python preparar_mysql.py
-----------------------------
Passo 2: (Opcional) Baixar o CSV de Munic√≠pios Se o municipios.csv n√£o estiver na pasta, este script ir√° baix√°-lo.

Bash
---------------------
python baixar_csv.py
---------------------
Passo 3: Executar o Pipeline Principal (ETL-A) Este √© o script principal. Ele far√° todo o processo: ler o JSON, analisar, transformar, enriquecer e carregar os dados no MongoDB e no MySQL.

Bash
------------------------
python carregar_dados.py
------------------------

Sa√≠da Esperada: O terminal exibir√° o progresso, incluindo a An√°lise Explorat√≥ria (EDA) e o log de carregamento dos 31 lotes no MySQL, finalizando com:

...
[Top 10 Munic√≠pios por Notifica√ß√£o (Nome)]
nome_municipio
S√£o Paulo                64604
S√£o Jos√© do Rio Preto    58881
Porto Alegre             55224
...

Conectando ao MongoDB...
Sucesso! 1502259 documentos inseridos no MongoDB.
------------------------------
Conectando ao MySQL...
Transformando dados para SQL (agrupando JSONs)...
...
Enviando lote 31 para o MySQL (1500001 a 1502259)...
Sucesso! Todos os 1502259 registros foram inseridos no MySQL.
